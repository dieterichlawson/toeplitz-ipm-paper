\documentclass{article}

\usepackage{graphicx} % Required to insert images
\usepackage{listings} % Required for insertion of code
\usepackage{courier} % Required for the courier font
\usepackage{todonotes}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage{enumerate}
\usepackage{hyperref}
\usepackage[margin=1.0in]{geometry}

\bibliographystyle{alpha}

% homework section framework, etc...
\input defs.tex
\title{Implementation of interior-point methods for positive semi-definite Toeplitz cone programming}
\author{Matt Staib, Dieterich Lawson}
\begin{document}
\maketitle
\large
\section{Introduction}
Consider the cone of positive-semidefinite Toeplitz matrices
\[
  \toepcn_n = \{x \in \reals^n \mid \toep(x) \geq 0\}
\]
with $\toep(x)$ defined as

\[
  \toep(x)_{ij} = \begin{cases}
      x_{|i-j|+1} &  0 \leq |i-j| \leq n-1 \\
      0 & \mbox{otherwise}
\end{cases}.
\]

In words, $\toep (x)$ is the square Toeplitz matrix resulting from taking the $i$th
entry of $x$ as the $i$th sub- and super-diagonal. This cone appears in various applications
in signal processing. In super-resolution, total-variation denoising is tightly
linked to solving the feasibility problem 
\begin{equation}\label{superresolution}
  \begin{array}{ll}
    \mbox{find}    & Q \text{ hermitian}\\
    \mbox{subject to } & \begin{bmatrix} Q & \nu \\ \nu^* & 1 \end{bmatrix} \in S_n^+\\
                       & \mathcal T^*(Q) = d^2 e_1,
  \end{array}
\end{equation}
where $\mathcal T^*(M)_j = \sum_{i=1}^{n-j+1} M_{i, i+j-1}$ \cite{fernandez2014convex}.
Note that the constraints force $Q$ to be Toeplitz, so it should be possible to write 
problem \ref{superresolution} as a modified version of a Toeplitz semidefinite cone problem, with a cone that is the Euclidean product between $\toepcn$ and an inequality constraint. As we will discuss in the next section, \cite{alkire2002convex} presents some signal processing problems whose dual problems have a feasible set which is, up to affine transformation, the Euclidean product of $\toepcn$ and other more standard cones.

In this paper we investigate methods for cone programming
over $\toepcn_n$, i.e. we present methods for solving problems of the form

\begin{equation}\label{primal}
  \begin{array}{ll}
    \mbox{minimize}    & c^Tx \\
    \mbox{subject to } & Ax = b \\
                       & x \in \toepcn_n. 
  \end{array}
\end{equation}
where $x\in \reals^n$ is the optimization variable, $c \in \reals^n$, $A \in \reals^{m\times n}$, 
and $b \in \reals^m$. The central difficulty for problems of this form is that $\toepcn_n$
is not symmetric, so much of the standard primal-dual machinery becomes unweildly.

The remainder of this paper is organized as follows. We first explore the properties of 
$\toepcn_n$, deriving its dual and showing that it is not symmetric.  We discuss a suitable 
barrier for $\toepcn_n$ and its use in two different algorithms that make speed gains 
over the standard primal-dual interior-point method by not calculating the derivatives
of the dual barrier. Finally we present some numeric results from these algorithms. 

\section{The Positive Semi-Definite Toeplitz Cone}

To characterize the dual of $\toepcn_n$ we show that $\toepcn_n$ is the dual of the 
cone of finite autocorrelation sequences. A finite autocorrelation sequence is a vector
$x \in \reals^n$ with a $y \in \reals^n$ such that 
\[
  x_k = \sum_{i=1}^{n-k} y_iy_{i+k} \quad k=1,\ldots,n.
\] 
For any positive scalar $\alpha$, $\alpha x$ can be represented as above 
by $\alpha^{1/2}y$, so the set of finite autocorrelation sequences forms a cone.
The dual of $\corrcn_n$ is 
\[
  \corrcn^*_n = \{z \in \reals^n \mid z^Tx \geq 0 \text{ for } x \in \corrcn_n\}.
\]
Because $x$ is a finite autocorrelation sequence, $z^Tx \geq 0$ for all $x \in \corrcn_n$
if and only if
\[
  \sum_{i=1}^n z_i \left(\sum_{i=1}^{n-k} y_iy_{i+k}\right) \geq 0.
\]
This summation can be expressed in terms of the Toeplitz form of $z$ ---
the above is true if and only if $y^TT_n(z)y \geq 0$ for all $y \in \reals^n$. Thus
$\corrcn^*_n$ is exactly the positive semi-definite Toeplitz cone, $\toepcn_n$. Nonempty,
closed, convex cones are reflexive, so $\toepcn_n^* = \corrcn_n$, and $\toepcn_n$ is not
symmetric.

The cone $\toepcn_n$ posesses a $\theta$ self-concordant $n$-logarithmically homogenous barrier function
\[
\phi_n(x) = - \log \det T_n(x).
\]
A $n$-logarithmically homogenous function satisfies
\[
 \phi_n(tx) = -n \log t + \phi_n(x).
\]

The cone $\toepcn_n$ is of particular practical interest because there are fast methods for evaluating
$\phi_n$, its gradient, and its Hessian, as detailed in \cite{alkire2002convex}. The motivation for this
paper is the desire to solve cone problems like (\ref{primal}) without evaluating the
gradient or Hessian of the dual barrier, which would be very expensive. Instead, we develop
techniques that use only the derivatives of the primal barrier function which we can evaluate
quickly using the methods given in \cite{alkire2002convex}.

\section{The Barrier Method}

We turn now to interior point methods and their suitability for
solving non-symmetric cone problems. Consider the following problem, which is slightly 
more general than (\ref{primal})

\begin{equation}\label{primalgen}
  \begin{array}{ll}
    \mbox{minimize}    & c^Tx \\
    \mbox{subject to } & Ax = b \\
                       & x \in K
  \end{array}
\end{equation}
where all variables are as in (\ref{primal}), and $K$ is a proper (closed, convex, solid, pointed) cone 
possessing a self-concordant and $\theta$-logarithmically homogenous barrier function, $\phi$. The
dual of (\ref{primalgen}) is
\begin{equation}\label{dual}
  \begin{array}{ll}
    \mbox{maximize}    & -b^T\lambda \\
    \mbox{subject to } & c + A^T\lambda + \nu = 0 \\
                       & \nu \in K^* \\
  \end{array}
\end{equation}
where $\lambda\in \reals^m, \nu \in \reals^n$ and $K^*$ is the dual cone of $K$. We assume
that (\ref{primalgen}) and (\ref{dual}) satisfy the interior point condition, i.e. that there
exists a strictly feasible $(x^0,\lambda^0,\nu^0)$ that satisfies
\[
 Ax^0=b,\; x^0 \in \mathbf{int} K, \; c+ A^T\lambda^0 + \nu^0 = 0,\; \nu^0 \in \mathbf{int} K^*.
\]

The \emph{barrier method} is an interior-point method that solves (\ref{primalgen}) by using
$\phi$ to make the cone constraint implicit in the objective. Using equality-constrained
Newton's method, the barrier method solves a series of problems of the form

\begin{equation}\label{primalt}
  \begin{array}{ll}
    \mbox{minimize}    & tc^Tx + \phi(x)\\
    \mbox{subject to } & Ax = b
  \end{array}
\end{equation}
where $t \in \reals,\;t >0$. For each $t >0$, (\ref{primalt}) has a unique minimizer \cite{BoV:04},
which defines the \emph{primal central path}
\[
  x^*(t) = \arg\min_x\{tc^Tx + \phi(x) \mid Ax=b\}.
\]
Each point on the primal central path is associated with a dual-feasible point which
can be used to lower-bound the optimal value of (\ref{primalgen}). To see this note that
any minimizer of (\ref{primalt}) $x^*(t)$ must satisfy the
optimality conditions
\[
  tc + \nabla\phi(x^*(t)) + A^Ty = 0 ,\; Ax^*(t) = b ,\; x^*(t) \in K
\]
for some $y\in\reals^m$. It can be shown that if  $x \in \mathbf{int} K$ then
$\nabla\phi(x) \in K^*$ \cite{alkire2002convex}. Thus, from the optimality conditions we 
see that $\nabla\phi(x^*(t))/t$, $y/t$ are feasible for the dual, (\ref{dual}).
Plugging $y/t$ into the dual objective and subtracting it from the primal gives
\[
  c^Tx^*(t) + b^T(y/t) =  x^*(t)\nabla\phi(x^*(t))/t = \nu/t
\]

This bounds the sub-optimality of $x^*(t)$ as
\[
  c^Tx^*(t) - p^* \leq c^Tx^*(t) + b^T(y/t) = \theta/t 
\]
where $p^*$ is the optimal value of (\ref{primal}). So, in summary we can solve a sequence of 
problems of the form (\ref{primalt}) with equality-constrained Newton's
method until $\theta/t$ is less than our desired accuracy. 

Alkire and Vandenberghe \cite{alkire2002convex} use the barrier method to solve
the Toeplitz cone problem that arises as the dual of autocorrelation cone
problems. A natural improvement would be to use a primal-dual interior point
method, where we stay within a neighborhood of the central path instead of on
the central path, but such a method would require evaluating both the primal
and dual barrier derivatives which as we discussed earlier would be
computationally expensive. The barrier method presented here avoids this,
allowing us to only evaluate the gradient and Hessian of the primal barrier
which we can do efficiently.

\section{A Predictor-Corrector Method}
In \cite{nesterov2006towards}, Nesterov presents an algorithm for solving a general
primal-dual cone problem, i.e. when the cone is not necessarily symmetric. This
method involves a centering step based on the primal, and uses the dual barrier
only in computing an appropriate step size. While the usual gradient and
Hessian are needed for the primal barrier, we only need the value of the dual
barrier. In fact, per Nesterov, the value of the dual barrier need not be terribly accurate.

In our case, for the standard log determinant barrier function for the semidefinite cone, we need to compute the conjugate
\begin{equation}
f_*(s) = \max_{x \in \mathcal T_n} \{ s^T x + \log\det(\text{toeplitz}(x))\}.
\end{equation}
For this barrier, in the case of the semidefinite cone, we have an explicit
form for the conjugate. When we further constrain $x$ to the Toeplitz cone,
though, we no longer know of a closed-form solution. In practice we solve this
using Newton's method.

The most computationally-intensive part of Nesterov's algorithm is the
computation of a step size $\alpha$ such that $\Omega(z + \alpha \delta z) =
\Omega(z) + C$ for a function $\Omega(z)$ involves a sum of the barrier and
conjugate barrier. Again, we know of no closed-form solution, so we compute
$\alpha$ using the bisection method.

\section{Numerical Results}
Our implementation is hosted on Github at \url{github.com/mstaib/toeplitz-ipm}.
Unfortunately we were unable to produce a fully working variation of Nesterov's
algorithm. We encountered difficulties with poorly-conditioned Hessians among
other things. We tested the specific problem with $c = \mathbf 1 \in \mathbb
R^4$, $A \in \mathbb R^{3\times 4}$, and $b = A \cdot (8,4,2,1)^T$. Given a
starting feasible point, our method managed 10 iterations in about 2 seconds,
approximately converging to an objective value of 12.83 before this
inexplicably jumped up to 14.7 on the 10th iteration. Each point produced was
strictly feasible. In contrast, CVX took only 0.3 seconds to produce a better
objective value of 11.04.

%\newpage
\bibliography{project}

\end{document}
